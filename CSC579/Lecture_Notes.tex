%%This is a very basic article template.
%%There is just one section and two subsections.
\documentclass{article}
\usepackage[margin=0.5in]{geometry}
\usepackage{units}
\usepackage{amsfonts}

\newcommand\TP{\mathit{TP}}
\newcommand\FN{\mathit{FN}}
\begin{document}


\section{CSC579 : Class Notes}
\subsection {Administrivia}
\subsection{Probability Review}
Put review of probability here. 
\subsection{ Stochastic Processes and Markov Models }
	\subsubsection{Stochastic Procsses}
	  A family of Random vars $\{ X(t) : t\in T\}$ 
	\\\indent t is normally time  
    \\\indent T is called the index set 
    \\\indent T can be discrete $\{ 0,1,2,3 \ldots \}$ or cont $\{ t : 0 \le t \le \infty \}$
	\\\indent the set  $\{ X(t) : t \in T \}$ is the State Space 
	\\
	\subsubsection{Time Dependence}
	Stationarity -- invariant under a shift of time origin. 
	\[Prob\{ X(t_1) \le t_1, X(t_2) \le t_2 \ldots, X(t_n) \le t_n \} = \]
	\[Prob\{ X(t_1 + \alpha ) \le t_1, X(t_2 + \alpha ) \le t_2 \ldots, X(t_n +\alpha) \le t_n \}\]
	Homogenerity -- invariant under time elapsed from origin
	\\
	\subsubsection{Markov process}
	A stochastic process who satisfies Markov or Memoryless property. 
	\[Prob\{ X_{n+1} = x_{n+1} | X_n = x_n, X_{n-1} = x_{n-1} \ldots , X_0 = x_0 \}\]
	\[= Prob\{ X_{n+1} = x_{n+1} | X_n = x_n\}\]
	\\Single step transition probability :
	\[Prob\{X_{n+1} = j | X_n = i \} = p_{ij}(n) \]
	\\Transition Probability Matrix : 
	\[ \left( \begin{array}{ccc}
            p_{00}(n) & p_{01}(n) & p_{02}(n) \\
			p_{10}(n) & p_{11}(n) & p_{12}(n) \\
			p_{20}(n) & p_{21}(n) & p_{22}(n) 
	\end{array} \right)\] 
	(Row is from, Column is to, p10 is from 1 to 0.)
 	\\$p_{ab}(n)$ is the probability to move from a to b at timestep n.
	\\
 	\\If the markov chain is homogeneous, this matrix is the same for all values of n. 
	\\$$\sum\limits_{all j}{p_{ij}(n)} = 1$$
	\\For a homogeneous markov chain, $p_{ij} p_{jk} p_{kl}$ is the probability of traveling $i\rightarrow j\rightarrow k\rightarrow l$
	\\\subsubsection{Example : Social Modility Model }
	Partition into upper middle and lower class. 
	
	\[P = \bordermatrix{   
              & U    & M    & L     \cr
            U & 0.45 & 0.50 & 0.05 \cr
			M & 0.15 & 0.65 & 0.20 \cr
			L & 0.00 & 0.50 & 0.50  }
    \]

	$$Prob\{ X_{n+2} = U, X_{n+1} = M | X_n = L \} = P_{ML}P_{MU} = 0.5 \times 0.15 = 0.075 $$
 	\subsubsection{Example : The Ehrenfest Model}
 	Two buckets containing N balls - choose one ball at random and move to the other bucket, let k indicate the number of buckets in bucket 1. 
 	\[ Prob\{ X_{n+1} = k + 1 | X_{n} = k \} = \frac{ N - k}{N}, \quad Prob\{ X_{n+1} = k-1 | X_n \} = \frac{k}{N}, \quad k \geq 1.\] 
 	\[p_{01} = 1 \quad p_{12} = \frac{5}{6} \quad p_{23} = \frac{4}{6} \quad \ldots \quad etc. \]
 	\subsubsection{Example : A Non-homogeneous example }
 	\[p_{aa}(n) = p_{bb}(n)= 1/n ,\quad p_{ab}(n) = p_{ba}(n) = \frac{n - 1}{n}, \quad \forall n \in N \]
 	\[ P(n) = \left( \begin{array}{cc}
            \nicefrac{1}{n} & \nicefrac{(n - 1)}{n}  \\
			\nicefrac{(n - 1)}{n} & \nicefrac{1}{n}  
	\end{array} \right)\]  
	h
	As time increases the probability of switching states decreases approaching 0 and n approaches \(\infty\)
	\subsubsection{Making Markov out of non-memoryless stochastic processes}
	Consider the belfast weather morkov chain. If it were the case that the tranisition probaility matrix of a state where it was 2 rainy days in a row was
	different than a single rainy day, then our stochastic process is no longer memoryless. We can flatten this out by creating a new state to accomondate, called
	RR, making our states $\{S,C,R,RR\}$. This is similar to flattening out a non-deterministic state machine to a deterministic one - it could result in a
	infinite number of states - but is sometime usefull to make markov chains out of non-memoryless stochastic processes. 
	\\
	\\If the last k steps of a stochastic process are important, than stochastic process with s steps can be flattened into a markov chain with $s^k$ states.
	\\
	\\When a stochastic process is dependent on k previous steps it is called a k-dependent process.  
	\subsubsection{The Embedded Markov Chain (Analysis of propensity to move, and normalizing with no self loops)}
	Diagonal elements of a TPM can be non-zero, Soujour time is the amount of time spent in a state before moving out. 
	\\For a homogenous soujourn time, the soujour time must be geometric.
	\\
	\\Geometric random variable : 
	\[ \alpha > 0,\quad \alpha(1-\alpha) ^ { n -1 }, \quad n \in \mathbb{N} \]
	\\Similar to tossing a coin weighted coin until you get heads, stay in state until you get heads.
	\\
	\\Prbability of leaving a state i :
	\[ \sum\limits_{i\neq j}{ p_{ij}} = (1 - p_{ii}) \]
	\\Probability that we spend k steps in state i:
	\[ Prob\{R_i=k\} = (1 - p_{ii})p_{ii}^{k-1}\]
	\[ E[R_i] = \frac{1}{1-p_{ii}}, \quad Var[R_i] =\frac{p_{ii}}{(1-p_{ii})^2} \]
	\\We can normalize a markov chain to remove self loops $\Longrightarrow$ replace $p_{ij}, i \neq j$ with $p_{ij} / (1 - p_{ii} )$, set diagonal to zeros.
	\\The new matrix is still stochastic :
	\[\sum\limits_{i\neq j}{\frac{p_{ij}}{1 - p_{ii}}} = \frac{1}{1-p_{ii}}, \quad\sum\limits_{i\neq j}{p_{ij}} =\frac{1}{1-p_{ii}} ( 1-p_{ii} )= 1\]
	\\Embedded markov chains, or normalized markov chains lose information.  Recoding the Sojourn times for each nodes allows us to go backwards and know
	something about the self loops in an embedded markov chain. 
	\subsubsection {Chapman-Kolmogorov Equation}
	Belfast process with states $\{R,S,C\}$. 
	\\Probability that its couldy two days from now given today is sunny: 
	\[ \sum\limits_{w=R,C,S}{p_{Sw}p_{wC}}. \]
	\\Find this sum by computing the dot product of the row corresponding to all states leaving the initial state, and the column corresponding to all state
	entering the destination state. 
	\[P = \bordermatrix{   
              & S    & C    & R    \cr
            S & a & d & g \cr
			C & b & e & h \cr
			R & c & f & i } 
			, \quad V_{Sw} = <a,d,g>
			, \quad V_{wC} = <d,e,f>
			, \quad \sum\limits_{w=R,C,S}{p_{Sw}p_{wC}} = V_{Sw}V_{wC}
    \]
	\\The cross product of the matrix is the dot product of all of these elements so $P^k$ is the probability of arriving at a state k steps down
	\[P^2= \bordermatrix{   
              & S    & C    & R    \cr
            S & V_{Sw}V_{wS} & V_{Sw}V_{wC} & V_{Sw}V_{wR} \cr
			C & V_{Cw}V_{wS} & V_{Cw}V_{wC} & V_{Cw}V_{wR} \cr
			R & V_{Rw}V_{wS} & V_{Rw}V_{wC} & V_{Rw}V_{wR} }  
	 ,\quad P^3= \bordermatrix{   
              & S    & C    & R    \cr
            S & V_{Sw}V_{wx}V_{xS} & V_{Sw}V_{wx}V_{xC} & V_{Sw}V_{wx}V_{xR} \cr
			C & V_{Cw}V_{wx}V_{xS} & V_{Cw}V_{wx}V_{xC} & V_{Cw}V_{wx}V_{xR} \cr
			R & V_{Rw}V_{wx}V_{xS} & V_{Rw}V_{wx}V_{xC} & V_{Rw}V_{wx}V_{xR} }  
	,\quad etc\ldots \]
	\\Limit as k appraoches infinity is the total probability to be in a state after a long time.  
	\\Generalize to compute probablities after discrete time steps 
	\[ p_{ij}^{m} = Prob\{ X_{n+m} = j | X_{n} = i \} \]
	\\Can be obtain from single step probabilities (Without raising matrixes to powers)
	\[ p_{ij}^{(m)} = \sum\limits_{\forall k}{p_{ik}^{(l)}p_{kj}^{(m-l)}}, 0 < l < m. \rightarrow P^{(m)} = P^{(l)}P^{(m-l)}\]
	\\This is the Chapman - Kolmogorov equation.
	\\Non homogeneous matrixes must accomodate n. 
\subsubsection{Postion Probability Vector ``\pi''}
	Let \(\pi_i^{(k)}\) be the probability that a markov chain is in poition i at time step k. \(k = 0\) is the initial step. 
	\\\indent\(\pi^{(k)}\) is the column vector of these probabilites. 
    \\\indent\(\pi^{(k+1)} = \pi^{(k)}P(k)\) or in a homogenous Markov chain \(\pi^{(k+1)} = \pi^{(k)}P\)
    \\
    \\Example:
    \[\pi^{(k+1)} = \pi^{(k)}P(k) = \left(0,.5,.5\right) \left( \begin{array}{ccc}
			0.8&0.15&0.05  \\
			0.7&0.2&0.1  \\
			0.5&0.3&0.2   
	\end{array} \right) = \left(0.6, 0.25, 0.15\right).\]
	\\
	\\In a general for a homogenous or a non-homogenous example :
	\[\left(\pi^{m} =\pi^{(0)}P^{(m)} \right)\mbox{ or }\left( \pi^{m} = \pi^{(0)}\prod\limits_{i=0}^{m}{P(i)} \right)\mbox{ in a non-homogenous example}\]
	\\
	\\It is useful to look at the limit as timestep approached infinity when this is available.
	\[ \lim_{n\rightarrow\infty}{\pi^{(n)}} = \pi^{(0)}\lim_{n\rightarrow\infty}{P^{(n)}}\]
	\\
	\\ Example : Kafkaesque prison. A prisoner must draw 6 cards. If he ever draws 3 consecutive, he is executed. If he get to 6 cards without drawing 3 red cards
	he lives. 
	\\
	\\ Create 4 states $\{R_0, R_1, R_2, R_3\}$, where the subscript refers to the consectutive number of reds seen. 
	\\Use the following tranistion probability matrix (Note this example is homogenous.)
	\[P= \bordermatrix{   
                & R_0 & R_1 & R_2  & R_3 \cr
            R_0 & 0.5 & 0.5 & 0    & 0   \cr
            R_1 & 0.5 & 0   & 0.5  & 0   \cr
            R_2 & 0.5 & 0   & 0    & 0.5 \cr
            R_3 & 0   & 0   & 0.5  & 1
       },\quad \pi_0 = \left(1,0,0,0\right)\]
       \[P^6 = \left(\matrix{
         0.375 & 0.203 & 0.109 & 0.312 \cr
         0.312 & 0.171 & 0.093 & 0.421 \cr
         0.203 & 0.109 & 0.062 & 0.062 \cr
         0     & 0     & 0     & 1.0  
       }\right), \quad \pi_0P^6 = \left( 0.375, 0.203, 0.109, 0.312\right)\]
     Chance of death is 31.2\%.
     
     
	
\end{document}
